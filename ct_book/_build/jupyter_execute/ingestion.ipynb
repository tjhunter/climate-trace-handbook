{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion and formatting\n",
    "\n",
    "This notebook explains how to convert the Climate TRACE dataset to a format that is more appropriate for data science. \n",
    "\n",
    "```{note}\n",
    "This section is relevant for data engineers, or data scientists who want to understand how the data \n",
    "has been prepared. Skip if you just want to access the final, prepared data.\n",
    "```\n",
    "\n",
    "The original data from Climate TRACE is offered as a series of CSV files bundled in ZIP archives. That format is universally understood, but it is not the most effective for effective analysis with data science tools. In particular, it is large: the source data, uncompressed, is about 20GB. This is the size at which most people would consider this project to be \"big data\" or at least \"medium data\". With the proper choice of data storage, we will bring it down to a breezy \"small data\" without losing information along the way.\n",
    "\n",
    "Instead, we are going to use the Parquet format. This format has a number of advantages:\n",
    "- it is _column-based_ : data systems can process big chunks of data at once, rather than line by line. Also, depending on the information requested, systems will read only the relevant columns and skip the rest very effectively\n",
    "- it is _universal_ : most modern data systems will be able to read it\n",
    "- it is _structured_ : basic information about numbers, categories, ... are preserved. It \n",
    "\n",
    "\n",
    "Looking at the code, we are performing a few tricks:\n",
    "\n",
    "_Compacting the data_ We minimize the size of the files by taking advantage of its structures. In particular, we know in many cases that values are part of known enumerations (sectors, ...). We replace all these by `polars.Enumeration`s. Not only this makes files smaller, but it also allows data systems to make clever optimization for complex operations such as joining.\n",
    "\n",
    "_Lazy reading_ If we were to read all the source data using a traditional system such as Excel or Pandas, we would require a serious amount of memory. The files themselves are more than 5GB. Polars is capable of reading straight from the zip file in a streaming fashion. This is what Polars calls a Lazy dataframe, or LazyFrame. Even when doing complicated operations such as joining the source files with the confidence information, Polars only uses 3GB of memory on my machine. In fact, this way of working is so fast that the `ctrace` package directly reads all the country emissions data from the zip files in less than a second.\n",
    "\n",
    "_Using known enumerations_ You will see in the source code that nearly all the variables such as column names, names of gas and sectors, etc. are replaced CONSTANT_NAMES such as `CH4`,.... You can use that to autocomplete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from ctrace.constants import *\n",
    "import ctrace as ct\n",
    "import pyarrow\n",
    "from dds import data_function\n",
    "import shutil\n",
    "import dds\n",
    "import huggingface_hub\n",
    "logging.getLogger(\"dds\").setLevel(logging.WARNING)\n",
    "dds.accept_module(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating optimized parquet files\n",
    "\n",
    "This first section creates files that are the most effective for reading and querying. The general approach is as follows:\n",
    "\n",
    "1. Join the source and source confidence CSV files and writes them as parquet files for each subsector\n",
    "2. Aggregate by year into a yearly parquet file\n",
    "3. Optimize this parquet file for reading\n",
    "\n",
    "This first command creates parquet files that join the source and source confidences for each subsector, and returns a list of all the created files.\n",
    "\n",
    "In this notebook, another trick is to define the transformations as _data functions_. In short, this code will only run if the source code changes. This makes rerunning the notebooks very fast, and only updating when something has changed in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:Opening path agriculture.zip co2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:sources:co2: agriculture.zip -> ['DATA/cropland-fires_emissions_sources.csv', 'DATA/enteric-fermentation-cattle-operation_emissions_sources.csv', 'DATA/enteric-fermentation-cattle-pasture_emissions_sources.csv', 'DATA/manure-left-on-pasture-cattle_emissions_sources.csv', 'DATA/manure-management-cattle-operation_emissions_sources.csv', 'DATA/rice-cultivation_emissions_sources.csv', 'DATA/synthetic-fertilizer-application_emissions_sources.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:opening agriculture.zip / DATA/cropland-fires_emissions_sources.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:opening agriculture.zip / DATA/cropland-fires_emissions_sources.csv and DATA/cropland-fires_emissions_sources_confidence.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:loading source <zipfile.ZipExtFile name='DATA/cropland-fires_emissions_sources.csv' mode='r' compress_type=deflate>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:loaded str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:recast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:loading source conf <zipfile.ZipExtFile name='DATA/cropland-fires_emissions_sources_confidence.csv' mode='r' compress_type=deflate>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:columns: ['source_id', 'source_name', 'iso3_country', 'sector', 'subsector', 'start_time', 'end_time', 'source_type', 'capacity', 'capacity_factor', 'activity', 'gas', 'emissions_factor', 'emissions_quantity', 'created_date', 'modified_date']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ctrace.data:source conf: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     (_, files) \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mload_source_compact()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m files\n\u001b[0;32m----> 6\u001b[0m \u001b[43mload_sources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/dds/_annotations.py:68\u001b[0m, in \u001b[0;36mdata_function.<locals>.decorator_.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DDSException(\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@data_function cannot be used with arguments. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments were passed to the function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but this function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         DDSErrorCode\u001b[38;5;241m.\u001b[39mARG_IN_DATA_FUNCTION,\n\u001b[1;32m     67\u001b[0m     )\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_keep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/dds/_api.py:52\u001b[0m, in \u001b[0;36mkeep\u001b[0;34m(path, fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeep\u001b[39m(\n\u001b[1;32m     46\u001b[0m     path: Union[\u001b[38;5;28mstr\u001b[39m, DDSPath, pathlib\u001b[38;5;241m.\u001b[39mPath],\n\u001b[1;32m     47\u001b[0m     fun: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, _Out],\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     50\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Out:\n\u001b[1;32m     51\u001b[0m     path \u001b[38;5;241m=\u001b[39m DDSPathUtils\u001b[38;5;241m.\u001b[39mcreate(path)\n\u001b[0;32m---> 52\u001b[0m     res: Optional[_Out] \u001b[38;5;241m=\u001b[39m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/dds/_api.py:199\u001b[0m, in \u001b[0;36m_eval\u001b[0;34m(fun, path, args, kwargs, dds_export_graph, dds_extra_debug, dds_stages)\u001b[0m\n\u001b[1;32m    195\u001b[0m extra_debug \u001b[38;5;241m=\u001b[39m dds_extra_debug \u001b[38;5;129;01mor\u001b[39;00m get_option(extra_debug_option)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _eval_ctx:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Not in an evaluation context, create one and introspect\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval_new_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_debug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/dds/_api.py:388\u001b[0m, in \u001b[0;36m_eval_new_ctx\u001b[0;34m(fun, path, args, kwargs, export_graph, extra_debug, stages)\u001b[0m\n\u001b[1;32m    382\u001b[0m kwargs_repr \u001b[38;5;241m=\u001b[39m OrderedDict(\n\u001b[1;32m    383\u001b[0m     [(key, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(arg))) \u001b[38;5;28;01mfor\u001b[39;00m (key, arg) \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    384\u001b[0m )\n\u001b[1;32m    385\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_new_ctx:Evaluating (eval) fun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m )\n\u001b[0;32m--> 388\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m _add_delta(t, ProcessingStage\u001b[38;5;241m.\u001b[39mEVAL)\n\u001b[1;32m    390\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_new_ctx:Evaluating (eval) fun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mload_sources\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@data_function\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data_sources\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sources\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     (_, files) \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_source_compact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m files\n",
      "File \u001b[0;32m~/work/climate-trace-handbook/src/ctrace/data.py:167\u001b[0m, in \u001b[0;36mload_source_compact\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    163\u001b[0m c_name \u001b[38;5;241m=\u001b[39m sname\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_emissions_sources.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_emissions_sources_confidence.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopening \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43m_load_source_conf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43msname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Remove all the empty strings, this provides better statistics and\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# removes unnecessary string compression.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m    171\u001b[0m     [\n\u001b[1;32m    172\u001b[0m         pl\u001b[38;5;241m.\u001b[39mwhen(pl\u001b[38;5;241m.\u001b[39mcol(pl\u001b[38;5;241m.\u001b[39mUtf8)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen_bytes() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m     ]\n\u001b[1;32m    177\u001b[0m )\n",
      "File \u001b[0;32m~/work/climate-trace-handbook/src/ctrace/data.py:253\u001b[0m, in \u001b[0;36m_load_source_conf\u001b[0;34m(s_fp, c_fp)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Workaround: some confidence records are duplicated:\u001b[39;00m\n\u001b[1;32m    248\u001b[0m c_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    249\u001b[0m     c_df\u001b[38;5;241m.\u001b[39mgroup_by(START_TIME, END_TIME, ISO3_COUNTRY, SOURCE_ID)\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;241m.\u001b[39magg(pl\u001b[38;5;241m.\u001b[39mfirst(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;241m.\u001b[39mshrink_to_fit()\n\u001b[1;32m    252\u001b[0m )\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ms_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcreated_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodified_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSUBSECTOR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mSTART_TIME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_TIME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mISO3_COUNTRY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOURCE_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGAS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshrink_to_fit()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/polars/dataframe/frame.py:7144\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, left_on, right_on, suffix, validate, join_nulls, coalesce)\u001b[0m\n\u001b[1;32m   7140\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected `other` join table to be a DataFrame, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m   7143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 7144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_nulls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin_nulls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoalesce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7156\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7157\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/climate-trace-nO4nxH9g-py3.10/lib/python3.10/site-packages/polars/lazyframe/frame.py:2029\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@data_function(\"/data_sources\")\n",
    "def load_sources():\n",
    "    (_, files) = ct.data.load_source_compact()\n",
    "    return files\n",
    "\n",
    "load_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with the loading, the data is partitioned by year. This is the most relevant for most users: most people are expected to look at specific years and sectors (especially the latest year). This reduces the amount of data to load.\n",
    "\n",
    "Let us have a quick peek at the data in one of these files. It looks already pretty good: a lot of the redundant data such as the enumerations has been deduplicated. All the enumeration data is now converted to integers, this is what `dictionary<values=string, indices=int32, ordered=0>` means. It is not quite ready for high performance however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/co2/cropland-fires_emissions_sources.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "source_id: uint64\n",
       "iso3_country: dictionary<values=string, indices=int32, ordered=0>\n",
       "sector: dictionary<values=string, indices=int32, ordered=0>\n",
       "subsector: dictionary<values=string, indices=int32, ordered=0>\n",
       "original_inventory_sector: dictionary<values=string, indices=int32, ordered=0>\n",
       "start_time: timestamp[ms, tz=UTC]\n",
       "end_time: timestamp[ms, tz=UTC]\n",
       "temporal_granularity: dictionary<values=string, indices=int32, ordered=0>\n",
       "gas: dictionary<values=string, indices=int32, ordered=0>\n",
       "emissions_quantity: double\n",
       "emissions_factor: double\n",
       "emissions_factor_units: large_string\n",
       "capacity: double\n",
       "capacity_units: large_string\n",
       "capacity_factor: double\n",
       "activity: double\n",
       "activity_units: large_string\n",
       "created_date: timestamp[ms, tz=UTC]\n",
       "modified_date: timestamp[ms, tz=UTC]\n",
       "source_name: large_string\n",
       "source_type: large_string\n",
       "lat: double\n",
       "lon: double\n",
       "other1: large_string\n",
       "other2: large_string\n",
       "other3: large_string\n",
       "other4: large_string\n",
       "other5: large_string\n",
       "other6: large_string\n",
       "other7: large_string\n",
       "other8: large_string\n",
       "other9: large_string\n",
       "other10: large_string\n",
       "other11: large_string\n",
       "other12: large_string\n",
       "other1_def: large_string\n",
       "other2_def: large_string\n",
       "other3_def: large_string\n",
       "other4_def: large_string\n",
       "other5_def: large_string\n",
       "other6_def: large_string\n",
       "other7_def: large_string\n",
       "other8_def: large_string\n",
       "other9_def: large_string\n",
       "other10_def: large_string\n",
       "other11_def: large_string\n",
       "other12_def: large_string\n",
       "geometry_ref: large_string\n",
       "conf_source_type: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_capacity: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_capacity_factor: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_activity: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_emissions_factor: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_emissions_quantity: dictionary<values=string, indices=int32, ordered=0>\n",
       "----\n",
       "source_id: [[10760226,10760226,10760226,10760226,10760226,...,10792989,10792989,10792989,10792989,10792989],[10792989,10792989,10792989,10792989,10792989,...,10812836,10812836,10812836,10812836,10812836],...,[11298418,11298418,11298418,11298418,11298418,...,11301822,11301822,11301822,11301822,11301822],[11301822,11301822,11301822,11301822,11301822,...,11303229,11303229,11303229,11303229,11303229]]\n",
       "iso3_country: [  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[1,1,1,1,1,...,23,23,23,23,23],  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[23,23,23,23,23,...,32,32,32,32,32],...,  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[234,234,234,234,234,...,238,238,238,238,238],  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[238,238,238,238,238,...,249,249,249,249,249]]\n",
       "sector: [  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],...,  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0]]\n",
       "subsector: [  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],...,  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8]]\n",
       "original_inventory_sector: [  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],...,  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null]]\n",
       "start_time: [[2021-01-01 00:00:00.000Z,2021-02-01 00:00:00.000Z,2021-03-01 00:00:00.000Z,2021-04-01 00:00:00.000Z,2021-05-01 00:00:00.000Z,...,2023-04-01 00:00:00.000Z,2023-05-01 00:00:00.000Z,2023-06-01 00:00:00.000Z,2023-07-01 00:00:00.000Z,2023-08-01 00:00:00.000Z],[2023-09-01 00:00:00.000Z,2023-10-01 00:00:00.000Z,2023-11-01 00:00:00.000Z,2023-12-01 00:00:00.000Z,2024-01-01 00:00:00.000Z,...,2021-12-01 00:00:00.000Z,2022-01-01 00:00:00.000Z,2022-02-01 00:00:00.000Z,2022-03-01 00:00:00.000Z,2022-04-01 00:00:00.000Z],...,[2023-09-01 00:00:00.000Z,2023-10-01 00:00:00.000Z,2023-11-01 00:00:00.000Z,2023-12-01 00:00:00.000Z,2024-01-01 00:00:00.000Z,...,2021-12-01 00:00:00.000Z,2022-01-01 00:00:00.000Z,2022-02-01 00:00:00.000Z,2022-03-01 00:00:00.000Z,2022-04-01 00:00:00.000Z],[2022-05-01 00:00:00.000Z,2022-06-01 00:00:00.000Z,2022-07-01 00:00:00.000Z,2022-08-01 00:00:00.000Z,2022-09-01 00:00:00.000Z,...,2024-08-01 00:00:00.000Z,2024-09-01 00:00:00.000Z,2024-10-01 00:00:00.000Z,2024-11-01 00:00:00.000Z,2024-12-01 00:00:00.000Z]]\n",
       "end_time: [[2021-01-31 00:00:00.000Z,2021-02-28 00:00:00.000Z,2021-03-31 00:00:00.000Z,2021-04-30 00:00:00.000Z,2021-05-31 00:00:00.000Z,...,2023-04-30 00:00:00.000Z,2023-05-31 00:00:00.000Z,2023-06-30 00:00:00.000Z,2023-07-31 00:00:00.000Z,2023-08-31 00:00:00.000Z],[2023-09-30 00:00:00.000Z,2023-10-31 00:00:00.000Z,2023-11-30 00:00:00.000Z,2023-12-31 00:00:00.000Z,2024-01-31 00:00:00.000Z,...,2021-12-31 00:00:00.000Z,2022-01-31 00:00:00.000Z,2022-02-28 00:00:00.000Z,2022-03-31 00:00:00.000Z,2022-04-30 00:00:00.000Z],...,[2023-09-30 00:00:00.000Z,2023-10-31 00:00:00.000Z,2023-11-30 00:00:00.000Z,2023-12-31 00:00:00.000Z,2024-01-31 00:00:00.000Z,...,2021-12-31 00:00:00.000Z,2022-01-31 00:00:00.000Z,2022-02-28 00:00:00.000Z,2022-03-31 00:00:00.000Z,2022-04-30 00:00:00.000Z],[2022-05-31 00:00:00.000Z,2022-06-30 00:00:00.000Z,2022-07-31 00:00:00.000Z,2022-08-31 00:00:00.000Z,2022-09-30 00:00:00.000Z,...,2024-08-31 00:00:00.000Z,2024-09-30 00:00:00.000Z,2024-10-31 00:00:00.000Z,2024-11-30 00:00:00.000Z,2024-12-31 00:00:00.000Z]]\n",
       "temporal_granularity: [  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],...,  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2]]\n",
       "gas: [  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],...,  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0]]\n",
       "emissions_quantity: [[4.8278737861685945,9.035360329705544,45.38064148636446,61.32296197461828,38.16818200021535,...,269.018757173264,175.31207076887267,91.39990500605398,58.724632699989535,80.81230569281288],[211.330903793614,292.1079909047341,194.5476801860844,84.82207853739389,43.68382457080989,...,220.01629117534543,128.19921825691085,181.80045288320784,525.6198997919303,724.2735952297198],...,[351.46495384672033,485.80552914236375,323.5527327530167,141.067810638062,72.65067773344693,...,11.962179491648724,6.242534827676018,8.85259422203629,25.59454398540237,35.26779027565498],[23.17575451210868,11.306731373197133,6.734582157427812,9.41144820628891,26.04592086520223,...,23.05403759079097,65.16548236458307,89.85554183215632,59.229313787334775,28.22216552802012]]\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarrow.parquet import read_table\n",
    "fname = load_sources()[0]\n",
    "print(fname)\n",
    "read_table(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating by year and optimizing the output\n",
    "\n",
    "The following block takes all the sector files and aggregates them by year. This is based on the expectation that most users will work on the latest year, and that some users will want to look into the trends across the years.\n",
    "\n",
    "Since these files will be read many times (every time we want to do a graph), it pays off to optimize them. The Parquet format is designed for fast reads of the relevant data. We will do two main optimizations: optimal compression, optimizing the row groups and adding statistics.\n",
    "\n",
    "\n",
    "\n",
    "_Compression_ Parquet allows some data to be compressed by columns. The first intuition is that, looking at each column of data separately, there will be more patterns and thus more opportunities to compress the data. The second intuition is that, in data-intensive application, reading the data is the bottleneck. It is then faster to read smaller compressed data in memory and then decompress it (losing a bit of time in compute), rather than reading larger, uncompressed data. Modern compression algorithms such as ZStandard or LZ4 are designed to be very effective at using a processor. Using them is essentially a pure gain in terms of processing speed.\n",
    "\n",
    "\n",
    "```{admonition} CTODO\n",
    "The year of a data record is defined by its start time. This may be different than the convention used by Climate Trace. To check.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/co2/cropland-fires_emissions_sources.parquet\n",
      "/tmp/co2/enteric-fermentation-cattle-operation_emissions_sources.parquet\n",
      "/tmp/co2/enteric-fermentation-cattle-pasture_emissions_sources.parquet\n",
      "/tmp/co2/manure-left-on-pasture-cattle_emissions_sources.parquet\n",
      "/tmp/co2/manure-management-cattle-operation_emissions_sources.parquet\n",
      "/tmp/co2/rice-cultivation_emissions_sources.parquet\n",
      "/tmp/co2/synthetic-fertilizer-application_emissions_sources.parquet\n",
      "/tmp/co2/non-residential-onsite-fuel-usage_emissions_sources.parquet\n",
      "/tmp/co2/residential-onsite-fuel-usage_emissions_sources.parquet\n",
      "/tmp/co2/forest-land-clearing_emissions_sources.parquet\n",
      "/tmp/co2/forest-land-degradation_emissions_sources.parquet\n",
      "/tmp/co2/forest-land-fires_emissions_sources.parquet\n",
      "/tmp/co2/net-forest-land_emissions_sources.parquet\n",
      "/tmp/co2/net-shrubgrass_emissions_sources.parquet\n",
      "/tmp/co2/net-wetland_emissions_sources.parquet\n",
      "/tmp/co2/removals_emissions_sources.parquet\n",
      "/tmp/co2/shrubgrass-fires_emissions_sources.parquet\n",
      "/tmp/co2/water-reservoirs_emissions_sources.parquet\n",
      "/tmp/co2/wetland-fires_emissions_sources.parquet\n",
      "/tmp/co2/coal-mining_emissions_sources.parquet\n",
      "/tmp/co2/oil-and-gas-production_emissions_sources.parquet\n",
      "/tmp/co2/oil-and-gas-refining_emissions_sources.parquet\n",
      "/tmp/co2/oil-and-gas-transport_emissions_sources.parquet\n",
      "/tmp/co2/aluminum_emissions_sources.parquet\n",
      "/tmp/co2/cement_emissions_sources.parquet\n",
      "/tmp/co2/chemicals_emissions_sources.parquet\n",
      "/tmp/co2/food-beverage-tobacco_emissions_sources.parquet\n",
      "/tmp/co2/glass_emissions_sources.parquet\n",
      "/tmp/co2/iron-and-steel_emissions_sources.parquet\n",
      "/tmp/co2/lime_emissions_sources.parquet\n",
      "/tmp/co2/other-chemicals_emissions_sources.parquet\n",
      "/tmp/co2/other-manufacturing_emissions_sources.parquet\n",
      "/tmp/co2/other-metals_emissions_sources.parquet\n",
      "/tmp/co2/petrochemical-steam-cracking_emissions_sources.parquet\n",
      "/tmp/co2/pulp-and-paper_emissions_sources.parquet\n",
      "/tmp/co2/textiles-leather-apparel_emissions_sources.parquet\n",
      "/tmp/co2/bauxite-mining_emissions_sources.parquet\n",
      "/tmp/co2/copper-mining_emissions_sources.parquet\n",
      "/tmp/co2/iron-mining_emissions_sources.parquet\n",
      "/tmp/co2/electricity-generation_emissions_sources.parquet\n",
      "/tmp/co2/domestic-aviation_emissions_sources.parquet\n",
      "/tmp/co2/domestic-shipping_emissions_sources.parquet\n",
      "/tmp/co2/international-aviation_emissions_sources.parquet\n",
      "/tmp/co2/international-shipping_emissions_sources.parquet\n",
      "/tmp/co2/road-transportation_emissions_sources.parquet\n",
      "/tmp/co2/domestic-wastewater-treatment-and-discharge_emissions_sources.parquet\n",
      "/tmp/co2/industrial-wastewater-treatment-and-discharge_emissions_sources.parquet\n",
      "/tmp/co2/solid-waste-disposal_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/cropland-fires_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/enteric-fermentation-cattle-pasture_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/manure-left-on-pasture-cattle_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/rice-cultivation_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/synthetic-fertilizer-application_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/net-forest-land_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/net-shrubgrass_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/net-wetland_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/water-reservoirs_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/coal-mining_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/oil-and-gas-refining_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/aluminum_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/cement_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/chemicals_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/other-manufacturing_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/pulp-and-paper_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/bauxite-mining_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/copper-mining_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/iron-mining_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/electricity-generation_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/domestic-aviation_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/domestic-shipping_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/international-aviation_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/international-shipping_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/road-transportation_emissions_sources.parquet\n",
      "/tmp/co2e_100yr/solid-waste-disposal_emissions_sources.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2021_co2.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2022_co2.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2023_co2.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2024_co2.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2021_co2e_100yr.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2022_co2e_100yr.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2023_co2e_100yr.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2024_co2e_100yr.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2021_co2.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2022_co2.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2022_co2.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2023_co2.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2023_co2.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2024_co2.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2024_co2.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2e_100yr.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2021_co2e_100yr.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2022_co2e_100yr.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2022_co2e_100yr.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2023_co2e_100yr.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2023_co2e_100yr.parquet'),\n",
       " ('/tmp/pre_climate_trace-sources_v3-2024-ct4_2024_co2e_100yr.parquet',\n",
       "  '/tmp/climate_trace-sources_v3-2024-ct4_2024_co2e_100yr.parquet')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_directory = \"/tmp\"\n",
    "years = ct.data.years\n",
    "version = ct.data.version\n",
    "gases = ct.constants.GAS_LIST\n",
    "\n",
    "@data_function(\"/write_data\")\n",
    "def write_data():\n",
    "    data_files = load_sources()\n",
    "    dfs = []\n",
    "    for tmp_name in data_files:\n",
    "        print(tmp_name)\n",
    "        df = pl.scan_parquet(tmp_name)\n",
    "        df = df.pipe(ct.data.recast_parquet, conf=True)\n",
    "        dfs.append(df)\n",
    "    ldf = pl.concat(dfs)\n",
    "    fnames = []\n",
    "    for gas in gases:\n",
    "        for year in years:\n",
    "            fname1 = f\"{write_directory}/pre_climate_trace-sources_{version}_{year}_{gas}.parquet\"\n",
    "            (\n",
    "                ldf.filter(c_start_time.dt.year() == int(year))\n",
    "                   .filter(c_gas == gas)\n",
    "                   .sort(by=[GAS, SECTOR, SUBSECTOR, ISO3_COUNTRY, SOURCE_ID])\n",
    "                   .sink_parquet(\n",
    "                    fname1,\n",
    "                    compression=\"zstd\",\n",
    "                    maintain_order=True,\n",
    "                    statistics=True,\n",
    "                )\n",
    "            )\n",
    "            fname = f\"{write_directory}/climate_trace-sources_{version}_{year}_{gas}.parquet\"\n",
    "            print(fname)\n",
    "            ds = pyarrow.dataset.dataset(fname1)\n",
    "            pyarrow.dataset.write_dataset(\n",
    "                ds,\n",
    "                base_dir=\"/tmp\",\n",
    "                basename_template=\"ds_{i}.parquet\",\n",
    "                format=\"parquet\",\n",
    "                partitioning=None,\n",
    "                min_rows_per_group=300_000,\n",
    "                max_rows_per_group=1_000_000,\n",
    "            )\n",
    "            shutil.copyfile(\"/tmp/ds_0.parquet\", fname)\n",
    "            fnames.append((fname1, fname))\n",
    "    return fnames\n",
    "\n",
    "write_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Optimizing row groups_ A parquet file is a collection of groups of rows, and these rows are organized column-wise along with some statistics. We can choose how many groups to create: the minimum is one group (all the data into a single group), which is the most standard. This is not optimal however: reading can only be done by one processor core at a time. If we have more, they will sit idle. This is why it is better to choose the number of groups to be close to the expected number of processor cores (10-100). When reading, each core will process a different chunk of the file in parallel.\n",
    "\n",
    "Polars cannot do this yet, so the code below directly calls the `pyarrow` package to restructure the final file, calling the function `pyarrow.dataset.write_dataset`. \n",
    "\n",
    "Here is the parquet files produced directly by Polars. It is the result of joining datasets which themselves are the result of reading many files (each by subsector). It is very fragmented (see the `num_row_groups` statistics below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2.parquet\n",
      "/tmp/climate_trace-sources_v3-2024-ct4_2021_co2.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7d8356541b20>\n",
       "  created_by: Polars\n",
       "  num_columns: 54\n",
       "  num_rows: 15184030\n",
       "  num_row_groups: 32\n",
       "  format_version: 1.0\n",
       "  serialized_size: 173153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fname_pre, fname_post) = write_data()[0]\n",
    "print(fname_pre)\n",
    "print(fname_post)\n",
    "parquet_file = pyarrow.parquet.ParquetFile(fname_pre)\n",
    "# print(parquet_file.metadata.row_group(0).column(2).statistics)\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file is more compact: only 58 row groups. It will be much faster to read (up to 50 times faster on my computer) because the readers do not need to gather information from each of the row groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7d832cd93d30>\n",
       "  created_by: parquet-cpp-arrow version 15.0.2\n",
       "  num_columns: 54\n",
       "  num_rows: 15184030\n",
       "  num_row_groups: 48\n",
       "  format_version: 2.6\n",
       "  serialized_size: 273069"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = pyarrow.parquet.ParquetFile(fname_post)\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Statistics_ Each row group in a parquet file has statistics. These statistics contain for each columns basic information such as minimum, maximum, etc. as you can see below. During a query, a data system first reads these statistics to check what blocks of data it should read. \n",
    "\n",
    "For example, the first row group only contains agriculture data (which you can infer from `min: agriculture` and `max: agriculture`). As the result, if a query is looking for waste data, it can safely skip this full block. \n",
    "\n",
    "Grouping the rows and creating statistics can dramatically reduce the amount of data being read and processed. Finding the right number of groups is a tradeoff between using more cores to read the data in parallel, and not having to read too many statistics descriptions. In the extreme case of the file created by Polars (5000 row groups), the statistics make up 40% of the file and can take up to 90% of the processing time! If your parquet file reads slowly, it is probably due to its internal layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.Statistics object at 0x7d8356541350>\n",
       "  has_min_max: True\n",
       "  min: 0.0905689899739461\n",
       "  max: 9955196.16948596\n",
       "  null_count: 0\n",
       "  distinct_count: None\n",
       "  num_values: 327680\n",
       "  physical_type: DOUBLE\n",
       "  logical_type: None\n",
       "  converted_type (legacy): NONE"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = pyarrow.parquet.ParquetFile(fname_post)\n",
    "parquet_file.metadata.row_group(0).column(12).statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know check that it works correctly. Let's load the newly created data instead of the default version stored on the internet, for the year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see the optimized version</p><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: polars_query Pages: 1 -->\n",
       "<svg width=\"3898pt\" height=\"190pt\"\n",
       " viewBox=\"0.00 0.00 3898.00 190.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 186)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-186 3894,-186 3894,4 -4,4\"/>\n",
       "<!-- p1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3890,-182 0,-182 0,-146 3890,-146 3890,-182\"/>\n",
       "<text text-anchor=\"middle\" x=\"1945\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [col(&quot;conf_source_type&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_source_type&quot;), col(&quot;conf_capacity&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_capacity&quot;), col(&quot;conf_capacity_factor&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_capacity_factor&quot;), col(&quot;conf_activity&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_activity&quot;), col(&quot;conf_emissions_factor&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_emissions_factor&quot;), col(&quot;conf_emissions_quantity&quot;).cast(Enum(Some(local), Physical)).alias(&quot;conf_emissions_quantity&quot;)]</text>\n",
       "</g>\n",
       "<!-- p2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>p2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3396.5,-110 493.5,-110 493.5,-74 3396.5,-74 3396.5,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"1945\" y=\"-88.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [col(&quot;iso3_country&quot;).strict_cast(Enum(Some(local), Physical)).alias(&quot;iso3_country&quot;), col(&quot;gas&quot;).cast(Enum(Some(local), Physical)).alias(&quot;gas&quot;), col(&quot;temporal_granularity&quot;).strict_cast(Enum(Some(local), Physical)).alias(&quot;temporal_granularity&quot;), col(&quot;subsector&quot;).strict_cast(Enum(Some(local), Physical)).alias(&quot;subsector&quot;), col(&quot;sector&quot;).strict_cast(Enum(Some(local), Physical)).alias(&quot;sector&quot;)]</text>\n",
       "</g>\n",
       "<!-- p1&#45;&#45;p2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p1&#45;&#45;p2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1945,-145.7C1945,-134.85 1945,-120.92 1945,-110.1\"/>\n",
       "</g>\n",
       "<!-- p3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>p3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2222,-38 1668,-38 1668,0 2222,0 2222,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"1945\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Parquet SCAN [/tmp/climate_trace&#45;sources_v3&#45;2024&#45;ct4_2024_co2.parquet]</text>\n",
       "<text text-anchor=\"middle\" x=\"1945\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\"> */54;</text>\n",
       "</g>\n",
       "<!-- p2&#45;&#45;p3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p2&#45;&#45;p3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1945,-73.81C1945,-62.98 1945,-49.01 1945,-38.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<LazyFrame at 0x7D83093E19C0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = ct.read_source_emissions(gas=CO2, year=2024, p=\"/tmp\")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 6M records for this year. This is spread across multiple gas and also multiple trips in the case of boats or airplanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>len</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>15183967</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "\n",
       " len      \n",
       " ---      \n",
       " u32      \n",
       "\n",
       " 15183967 \n",
       ""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.select(pl.len()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of distinct source IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sec = (sdf\n",
    ".group_by(SOURCE_ID, SECTOR)\n",
    ".agg(pl.len())\n",
    ".collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of sources outside FLU:\n",
    "\n",
    "```{admonition} CTODO\n",
    "This number does not match the official number on the Climate Trace website (395075 for 2022). Investigate.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>len</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>748730</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "\n",
       " len    \n",
       " ---    \n",
       " u32    \n",
       "\n",
       " 748730 \n",
       ""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_sec.filter(c_sector != FORESTRY_AND_LAND_USE).select(pl.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: no source is associated with multiple sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_id</th><th>sector</th></tr><tr><td>u64</td><td>u32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 2)\n",
       "\n",
       " source_id  sector \n",
       " ---        ---    \n",
       " u64        u32    \n",
       "\n",
       ""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_sec.group_by(SOURCE_ID).agg(c_sector.n_unique()).filter(pl.col(SECTOR) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: no annual source should be duplicated by gas. It used to be the case with V2 release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_id</th><th>gas</th><th>len</th></tr><tr><td>u64</td><td>enum</td><td>u32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 3)\n",
       "\n",
       " source_id  gas   len \n",
       " ---        ---   --- \n",
       " u64        enum  u32 \n",
       "\n",
       ""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sdf\n",
    ".filter(c_temporal_granularity ==\"annual\")\n",
    ".group_by(SOURCE_ID, GAS)\n",
    ".agg(pl.len())\n",
    ".filter(pl.col(\"len\") > 1)\n",
    ".sort(by=\"len\")\n",
    ".collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: emissions should always be defined. V2 used to have empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (26, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subsector</th><th>false</th></tr><tr><td>enum</td><td>u32</td></tr></thead><tbody><tr><td>&quot;rice-cultivation&quot;</td><td>684408</td></tr><tr><td>&quot;electricity-generation&quot;</td><td>106464</td></tr><tr><td>&quot;net-shrubgrass&quot;</td><td>682260</td></tr><tr><td>&quot;solid-waste-disposal&quot;</td><td>115500</td></tr><tr><td>&quot;domestic-shipping&quot;</td><td>99132</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;water-reservoirs&quot;</td><td>84408</td></tr><tr><td>&quot;net-forest-land&quot;</td><td>679632</td></tr><tr><td>&quot;international-aviation&quot;</td><td>58920</td></tr><tr><td>&quot;cement&quot;</td><td>26892</td></tr><tr><td>&quot;domestic-aviation&quot;</td><td>58920</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (26, 2)\n",
       "\n",
       " subsector               false  \n",
       " ---                     ---    \n",
       " enum                    u32    \n",
       "\n",
       " rice-cultivation        684408 \n",
       " electricity-generation  106464 \n",
       " net-shrubgrass          682260 \n",
       " solid-waste-disposal    115500 \n",
       " domestic-shipping       99132  \n",
       "                              \n",
       " water-reservoirs        84408  \n",
       " net-forest-land         679632 \n",
       " international-aviation  58920  \n",
       " cement                  26892  \n",
       " domestic-aviation       58920  \n",
       ""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = ct.read_source_emissions(CO2E_100YR, 2022, \"/tmp\")\n",
    "(sdf\n",
    " .select(c_emissions_quantity.is_null().alias(\"null_emissions\"), c_subsector, c_iso3_country)\n",
    " .group_by(c_subsector, \"null_emissions\")\n",
    " .agg(pl.len())\n",
    " .collect()\n",
    " .pivot(index=SUBSECTOR, on=\"null_emissions\", values=\"len\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data to the Hugging Face Hub\n",
    "\n",
    "As a final step, we make the datasets available on Hugging Face as a downloadable dataset.\n",
    "\n",
    "This step will only work if you have the credentials to upload the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub.utils\n",
    "try:\n",
    "    api = huggingface_hub.HfApi()\n",
    "    for (_, fpath) in write_data():\n",
    "        fname = os.path.basename(fpath)\n",
    "        print(fname, fpath)\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=fpath,\n",
    "            path_in_repo=fname,\n",
    "            repo_id=\"tjhunter/climate-trace\",\n",
    "            repo_type=\"dataset-REMOVE_ME\",\n",
    "        )\n",
    "except huggingface_hub.utils.HfHubHTTPError as e:\n",
    "    print(\"error\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
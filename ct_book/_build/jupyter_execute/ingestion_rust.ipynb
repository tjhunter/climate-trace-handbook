{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from ctrace.constants import *\n",
    "import ctrace as ct\n",
    "import pyarrow\n",
    "from dds import data_function\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import shutil\n",
    "import dds\n",
    "import huggingface_hub\n",
    "logging.getLogger(\"dds\").setLevel(logging.WARNING)\n",
    "dds.accept_module(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating optimized parquet files for source data\n",
    "\n",
    "This first section creates files that are the most effective for reading and querying. The general approach is as follows:\n",
    "\n",
    "1. Join the source and source confidence CSV files and writes them as parquet files for each subsector\n",
    "2. Aggregate by year into a yearly parquet file\n",
    "3. Optimize this parquet file for reading\n",
    "\n",
    "This first command creates parquet files that join the source and source confidences for each subsector, and returns a list of all the created files.\n",
    "\n",
    "In this notebook, another trick is to define the transformations as _data functions_. In short, this code will only run if the source code changes. This makes rerunning the notebooks very fast, and only updating when something has changed in the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/co2/cropland-fires_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/enteric-fermentation-cattle-operation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/enteric-fermentation-cattle-pasture_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/manure-left-on-pasture-cattle_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/manure-management-cattle-operation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/rice-cultivation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/synthetic-fertilizer-application_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/non-residential-onsite-fuel-usage_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/residential-onsite-fuel-usage_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/forest-land-clearing_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/forest-land-degradation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/forest-land-fires_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/net-forest-land_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/net-shrubgrass_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/net-wetland_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/removals_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/shrubgrass-fires_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/water-reservoirs_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/wetland-fires_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/coal-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/oil-and-gas-production_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/oil-and-gas-refining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/oil-and-gas-transport_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/aluminum_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/cement_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/chemicals_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/food-beverage-tobacco_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/glass_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/iron-and-steel_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/lime_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/other-chemicals_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/other-manufacturing_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/other-metals_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/petrochemical-steam-cracking_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/pulp-and-paper_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/textiles-leather-apparel_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/bauxite-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/copper-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/iron-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/electricity-generation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/domestic-aviation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/domestic-shipping_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/international-aviation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/international-shipping_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/road-transportation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/domestic-wastewater-treatment-and-discharge_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/industrial-wastewater-treatment-and-discharge_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2/solid-waste-disposal_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/cropland-fires_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/enteric-fermentation-cattle-pasture_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/manure-left-on-pasture-cattle_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/rice-cultivation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/synthetic-fertilizer-application_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/net-forest-land_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/net-shrubgrass_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/net-wetland_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/water-reservoirs_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/coal-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/oil-and-gas-refining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/aluminum_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/cement_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/chemicals_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/other-manufacturing_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/pulp-and-paper_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/bauxite-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/copper-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/iron-mining_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/electricity-generation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/domestic-aviation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/domestic-shipping_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/international-aviation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/international-shipping_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/road-transportation_emissions_sources.parquet'),\n",
       " PosixPath('/tmp/co2e_100yr/solid-waste-disposal_emissions_sources.parquet')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@data_function(\"/data_sources\")\n",
    "def load_sources():\n",
    "    (_, files) = ct.data.load_source_compact()\n",
    "    return files\n",
    "\n",
    "load_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with the loading, the data is partitioned by year. This is the most relevant for most users: most people are expected to look at specific years and sectors (especially the latest year). This reduces the amount of data to load.\n",
    "\n",
    "Let us have a quick peek at the data in one of these files. It looks already pretty good: a lot of the redundant data such as the enumerations has been deduplicated. All the enumeration data is now converted to integers, this is what `dictionary<values=string, indices=int32, ordered=0>` means. It is not quite ready for high performance however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/co2/cropland-fires_emissions_sources.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "source_id: uint64\n",
       "iso3_country: dictionary<values=string, indices=int32, ordered=0>\n",
       "sector: dictionary<values=string, indices=int32, ordered=0>\n",
       "subsector: dictionary<values=string, indices=int32, ordered=0>\n",
       "original_inventory_sector: dictionary<values=string, indices=int32, ordered=0>\n",
       "start_time: timestamp[ms, tz=UTC]\n",
       "end_time: timestamp[ms, tz=UTC]\n",
       "temporal_granularity: dictionary<values=string, indices=int32, ordered=0>\n",
       "gas: dictionary<values=string, indices=int32, ordered=0>\n",
       "emissions_quantity: double\n",
       "emissions_factor: double\n",
       "emissions_factor_units: large_string\n",
       "capacity: double\n",
       "capacity_units: large_string\n",
       "capacity_factor: double\n",
       "activity: double\n",
       "activity_units: large_string\n",
       "created_date: timestamp[ms, tz=UTC]\n",
       "modified_date: timestamp[ms, tz=UTC]\n",
       "source_name: large_string\n",
       "source_type: large_string\n",
       "lat: double\n",
       "lon: double\n",
       "other1: large_string\n",
       "other2: large_string\n",
       "other3: large_string\n",
       "other4: large_string\n",
       "other5: large_string\n",
       "other6: large_string\n",
       "other7: large_string\n",
       "other8: large_string\n",
       "other9: large_string\n",
       "other10: large_string\n",
       "other11: large_string\n",
       "other12: large_string\n",
       "other1_def: large_string\n",
       "other2_def: large_string\n",
       "other3_def: large_string\n",
       "other4_def: large_string\n",
       "other5_def: large_string\n",
       "other6_def: large_string\n",
       "other7_def: large_string\n",
       "other8_def: large_string\n",
       "other9_def: large_string\n",
       "other10_def: large_string\n",
       "other11_def: large_string\n",
       "other12_def: large_string\n",
       "geometry_ref: large_string\n",
       "conf_source_type: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_capacity: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_capacity_factor: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_activity: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_emissions_factor: dictionary<values=string, indices=int32, ordered=0>\n",
       "conf_emissions_quantity: dictionary<values=string, indices=int32, ordered=0>\n",
       "----\n",
       "source_id: [[10760226,10760226,10760226,10760226,10760226,...,10792989,10792989,10792989,10792989,10792989],[10792989,10792989,10792989,10792989,10792989,...,10812836,10812836,10812836,10812836,10812836],...,[11298418,11298418,11298418,11298418,11298418,...,11301822,11301822,11301822,11301822,11301822],[11301822,11301822,11301822,11301822,11301822,...,11303229,11303229,11303229,11303229,11303229]]\n",
       "iso3_country: [  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[1,1,1,1,1,...,23,23,23,23,23],  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[23,23,23,23,23,...,32,32,32,32,32],...,  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[234,234,234,234,234,...,238,238,238,238,238],  -- dictionary:\n",
       "[\"ABW\",\"AFG\",\"AGO\",\"AIA\",\"ALA\",...,\"ZWE\",\"ZNC\",\"UNK\",\"SCG\",\"XAD\"]  -- indices:\n",
       "[238,238,238,238,238,...,249,249,249,249,249]]\n",
       "sector: [  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],...,  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"agriculture\",\"buildings\",\"fluorinated-gases\",\"forestry-and-land-use\",\"fossil-fuel-operations\",\"manufacturing\",\"mineral-extraction\",\"power\",\"transportation\",\"waste\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0]]\n",
       "subsector: [  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],...,  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"synthetic-fertilizer-application\",\"textiles-leather-apparel\",\"water-reservoirs\",\"wetland-fires\",\"wood-and-wood-products\"]  -- indices:\n",
       "[8,8,8,8,8,...,8,8,8,8,8]]\n",
       "original_inventory_sector: [  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],...,  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null],  -- dictionary:\n",
       "[\"aluminum\",\"bauxite-mining\",\"biological-treatment-of-solid-waste-and-biogenic\",\"cement\",\"chemicals\",...,\"steel\",\"synthetic-fertilizer-application\",\"wastewater-treatment-and-discharge\",\"water-reservoirs\",\"wetland-fires\"]  -- indices:\n",
       "[null,null,null,null,null,...,null,null,null,null,null]]\n",
       "start_time: [[2021-01-01 00:00:00.000Z,2021-02-01 00:00:00.000Z,2021-03-01 00:00:00.000Z,2021-04-01 00:00:00.000Z,2021-05-01 00:00:00.000Z,...,2023-04-01 00:00:00.000Z,2023-05-01 00:00:00.000Z,2023-06-01 00:00:00.000Z,2023-07-01 00:00:00.000Z,2023-08-01 00:00:00.000Z],[2023-09-01 00:00:00.000Z,2023-10-01 00:00:00.000Z,2023-11-01 00:00:00.000Z,2023-12-01 00:00:00.000Z,2024-01-01 00:00:00.000Z,...,2021-12-01 00:00:00.000Z,2022-01-01 00:00:00.000Z,2022-02-01 00:00:00.000Z,2022-03-01 00:00:00.000Z,2022-04-01 00:00:00.000Z],...,[2023-09-01 00:00:00.000Z,2023-10-01 00:00:00.000Z,2023-11-01 00:00:00.000Z,2023-12-01 00:00:00.000Z,2024-01-01 00:00:00.000Z,...,2021-12-01 00:00:00.000Z,2022-01-01 00:00:00.000Z,2022-02-01 00:00:00.000Z,2022-03-01 00:00:00.000Z,2022-04-01 00:00:00.000Z],[2022-05-01 00:00:00.000Z,2022-06-01 00:00:00.000Z,2022-07-01 00:00:00.000Z,2022-08-01 00:00:00.000Z,2022-09-01 00:00:00.000Z,...,2024-08-01 00:00:00.000Z,2024-09-01 00:00:00.000Z,2024-10-01 00:00:00.000Z,2024-11-01 00:00:00.000Z,2024-12-01 00:00:00.000Z]]\n",
       "end_time: [[2021-01-31 00:00:00.000Z,2021-02-28 00:00:00.000Z,2021-03-31 00:00:00.000Z,2021-04-30 00:00:00.000Z,2021-05-31 00:00:00.000Z,...,2023-04-30 00:00:00.000Z,2023-05-31 00:00:00.000Z,2023-06-30 00:00:00.000Z,2023-07-31 00:00:00.000Z,2023-08-31 00:00:00.000Z],[2023-09-30 00:00:00.000Z,2023-10-31 00:00:00.000Z,2023-11-30 00:00:00.000Z,2023-12-31 00:00:00.000Z,2024-01-31 00:00:00.000Z,...,2021-12-31 00:00:00.000Z,2022-01-31 00:00:00.000Z,2022-02-28 00:00:00.000Z,2022-03-31 00:00:00.000Z,2022-04-30 00:00:00.000Z],...,[2023-09-30 00:00:00.000Z,2023-10-31 00:00:00.000Z,2023-11-30 00:00:00.000Z,2023-12-31 00:00:00.000Z,2024-01-31 00:00:00.000Z,...,2021-12-31 00:00:00.000Z,2022-01-31 00:00:00.000Z,2022-02-28 00:00:00.000Z,2022-03-31 00:00:00.000Z,2022-04-30 00:00:00.000Z],[2022-05-31 00:00:00.000Z,2022-06-30 00:00:00.000Z,2022-07-31 00:00:00.000Z,2022-08-31 00:00:00.000Z,2022-09-30 00:00:00.000Z,...,2024-08-31 00:00:00.000Z,2024-09-30 00:00:00.000Z,2024-10-31 00:00:00.000Z,2024-11-30 00:00:00.000Z,2024-12-31 00:00:00.000Z]]\n",
       "temporal_granularity: [  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],...,  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2],  -- dictionary:\n",
       "[\"annual\",\"other\",\"month\",\"week\",\"day\",\"hour\"]  -- indices:\n",
       "[2,2,2,2,2,...,2,2,2,2,2]]\n",
       "gas: [  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],...,  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0],  -- dictionary:\n",
       "[\"co2\",\"co2e_100yr\"]  -- indices:\n",
       "[0,0,0,0,0,...,0,0,0,0,0]]\n",
       "emissions_quantity: [[4.8278737861685945,9.035360329705544,45.38064148636446,61.32296197461828,38.16818200021535,...,269.018757173264,175.31207076887267,91.39990500605398,58.724632699989535,80.81230569281288],[211.330903793614,292.1079909047341,194.5476801860844,84.82207853739389,43.68382457080989,...,220.01629117534543,128.19921825691085,181.80045288320784,525.6198997919303,724.2735952297198],...,[351.46495384672033,485.80552914236375,323.5527327530167,141.067810638062,72.65067773344693,...,11.962179491648724,6.242534827676018,8.85259422203629,25.59454398540237,35.26779027565498],[23.17575451210868,11.306731373197133,6.734582157427812,9.41144820628891,26.04592086520223,...,23.05403759079097,65.16548236458307,89.85554183215632,59.229313787334775,28.22216552802012]]\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyarrow.parquet import read_table\n",
    "fname = load_sources()[0]\n",
    "print(fname)\n",
    "read_table(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating by year and optimizing the output\n",
    "\n",
    "The following block takes all the sector files and aggregates them by year. This is based on the expectation that most users will work on the latest year, and that some users will want to look into the trends across the years.\n",
    "\n",
    "Since these files will be read many times (every time we want to do a graph), it pays off to optimize them. The Parquet format is designed for fast reads of the relevant data. We will do two main optimizations: optimal compression, optimizing the row groups and adding statistics.\n",
    "\n",
    "\n",
    "\n",
    "_Compression_ Parquet allows some data to be compressed by columns. The first intuition is that, looking at each column of data separately, there will be more patterns and thus more opportunities to compress the data. The second intuition is that, in data-intensive application, reading the data is the bottleneck. It is then faster to read smaller compressed data in memory and then decompress it (losing a bit of time in compute), rather than reading larger, uncompressed data. Modern compression algorithms such as ZStandard or LZ4 are designed to be very effective at using a processor. Using them is essentially a pure gain in terms of processing speed.\n",
    "\n",
    "\n",
    "```{admonition} CTODO\n",
    "The year of a data record is defined by its start time. This may be different than the convention used by Climate Trace. To check.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/co2/cropland-fires_emissions_sources.parquet\n",
      "/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2.parquet\n",
      "/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2e_100yr.parquet\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(fname1)\n\u001b[1;32m     22\u001b[0m         (\n\u001b[1;32m     23\u001b[0m             ldf\u001b[38;5;241m.\u001b[39mfilter(c_start_time\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(year))\n\u001b[1;32m     24\u001b[0m                \u001b[38;5;241m.\u001b[39mfilter(c_gas \u001b[38;5;241m==\u001b[39m gas)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m         )\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# write_directory = \"/tmp\"\n",
    "# years = ct.data.years\n",
    "# version = ct.data.version\n",
    "# gases = ct.constants.GAS_LIST\n",
    "\n",
    "# data_files = load_sources()\n",
    "# dfs = []\n",
    "# for tmp_name in data_files[:1]:\n",
    "#     print(tmp_name)\n",
    "#     df = (pl.scan_parquet(tmp_name)\n",
    "#                         .with_columns(c_gas.cast(pl.Categorical(ordering=\"lexical\")),\n",
    "#                          c_sector.cast(pl.Categorical(ordering=\"lexical\")))\n",
    "# )\n",
    "#     # df = df.pipe(ct.data.recast_parquet, conf=True)\n",
    "#     dfs.append(df)\n",
    "# ldf = pl.concat(dfs)\n",
    "# fnames = []\n",
    "# for gas in gases:\n",
    "#     for year in years[:1]:\n",
    "#         fname1 = f\"{write_directory}/pre_climate_trace-sources_{version}_{year}_{gas}.parquet\"\n",
    "#         print(fname1)\n",
    "#         (\n",
    "#             ldf.filter(c_start_time.dt.year() == int(year))\n",
    "#                .filter(c_gas == gas)\n",
    "#                .with_columns(c_gas.cast(pl.UInt32()).alias(\"gas2\"),\n",
    "#                          c_sector.cast(pl.String()).alias(\"sector2\"))\n",
    "#                # .with_columns(c_gas.cast(pl.Categorical(ordering=\"physical\")),\n",
    "#                #           c_sector.cast(pl.Categorical(ordering=\"physical\")))\n",
    "#                .sort(by=[\"gas2\", \"sector2\",\n",
    "#                          # SUBSECTOR, ISO3_COUNTRY,\n",
    "#                          SOURCE_ID])\n",
    "#                # .sort(by=[SOURCE_ID])\n",
    "#                .drop([\"gas2\", \"sector2\"])\n",
    "#                # .collect()\n",
    "#                .sink_parquet(\n",
    "#                 fname1,\n",
    "#                 #compression=\"zstd\",\n",
    "#                 #maintain_order=True,\n",
    "#                 #statistics=True,\n",
    "#             )\n",
    "#         )\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_table(\"/tmp/pre_climate_trace-sources_v3-2024-ct4_2021_co2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_directory = \"/tmp\"\n",
    "years = ct.data.years\n",
    "version = ct.data.version\n",
    "gases = ct.constants.GAS_LIST\n",
    "\n",
    "@data_function(\"/write_data\")\n",
    "def write_data():\n",
    "    sort_keys = [GAS, SECTOR, SUBSECTOR, ISO3_COUNTRY, SOURCE_ID]\n",
    "    data_files = load_sources()\n",
    "    dfs = []\n",
    "    for tmp_name in data_files:\n",
    "        print(tmp_name)\n",
    "        df = pl.scan_parquet(tmp_name)\n",
    "        df = df.pipe(ct.data.recast_parquet, conf=True)\n",
    "        dfs.append(df)\n",
    "    ldf = pl.concat(dfs)\n",
    "    fnames = []\n",
    "    sort_keys2 = [c+\"2\" for c in sort_keys]\n",
    "    for gas in gases:\n",
    "        for year in years:\n",
    "            fname1 = f\"{write_directory}/pre_climate_trace-sources_{version}_{year}_{gas}.parquet\"\n",
    "            (\n",
    "                ldf.filter(c_start_time.dt.year() == int(year))\n",
    "                   .filter(c_gas == gas)\n",
    "                   .with_columns(*[pl.col(c).cast(pl.UInt32()).alias(c +\"2\") for c in sort_keys])\n",
    "                   .sort(by=sort_keys2)\n",
    "                   .drop(sort_keys2)\n",
    "                   .sink_parquet(\n",
    "                    fname1,\n",
    "                    compression=\"zstd\",\n",
    "                    maintain_order=True,\n",
    "                    statistics=True,\n",
    "                )\n",
    "            )\n",
    "            fname = f\"{write_directory}/climate_trace-sources_{version}_{year}_{gas}.parquet\"\n",
    "            print(fname)\n",
    "            # Polars does not allow yet finetuning the sizes of the groups.\n",
    "            # Creating them manually for the time being.\n",
    "            ds = pyarrow.dataset.dataset(fname1)\n",
    "            pyarrow.dataset.write_dataset(\n",
    "                ds,\n",
    "                base_dir=\"/tmp\",\n",
    "                basename_template=\"ds_{i}.parquet\",\n",
    "                format=\"parquet\",\n",
    "                partitioning=None,\n",
    "                min_rows_per_group=300_000,\n",
    "                max_rows_per_group=1_000_000,\n",
    "            )\n",
    "            shutil.copyfile(\"/tmp/ds_0.parquet\", fname)\n",
    "            fnames.append((fname1, fname))\n",
    "    return fnames\n",
    "\n",
    "write_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Optimizing row groups_ A parquet file is a collection of groups of rows, and these rows are organized column-wise along with some statistics. We can choose how many groups to create: the minimum is one group (all the data into a single group), which is the most standard. This is not optimal however: reading can only be done by one processor core at a time. If we have more, they will sit idle. This is why it is better to choose the number of groups to be close to the expected number of processor cores (10-100). When reading, each core will process a different chunk of the file in parallel.\n",
    "\n",
    "Polars cannot do this yet, so the code below directly calls the `pyarrow` package to restructure the final file, calling the function `pyarrow.dataset.write_dataset`. \n",
    "\n",
    "Here is the parquet files produced directly by Polars. It is the result of joining datasets which themselves are the result of reading many files (each by subsector). It is very fragmented (see the `num_row_groups` statistics below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fname_pre, fname_post) = write_data()[0]\n",
    "print(fname_pre)\n",
    "print(fname_post)\n",
    "parquet_file = pyarrow.parquet.ParquetFile(fname_pre)\n",
    "# print(parquet_file.metadata.row_group(0).column(2).statistics)\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file is more compact: only 58 row groups. It will be much faster to read (up to 50 times faster on my computer) because the readers do not need to gather information from each of the row groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = pyarrow.parquet.ParquetFile(fname_post)\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Statistics_ Each row group in a parquet file has statistics. These statistics contain for each columns basic information such as minimum, maximum, etc. as you can see below. During a query, a data system first reads these statistics to check what blocks of data it should read. \n",
    "\n",
    "For example, the first row group only contains agriculture data (which you can infer from `min: agriculture` and `max: agriculture`). As the result, if a query is looking for waste data, it can safely skip this full block. \n",
    "\n",
    "Grouping the rows and creating statistics can dramatically reduce the amount of data being read and processed. Finding the right number of groups is a tradeoff between using more cores to read the data in parallel, and not having to read too many statistics descriptions. In the extreme case of the file created by Polars (5000 row groups), the statistics make up 40% of the file and can take up to 90% of the processing time! If your parquet file reads slowly, it is probably due to its internal layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = pyarrow.parquet.ParquetFile(fname_post)\n",
    "parquet_file.metadata.row_group(0).column(12).statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know check that it works correctly. Let's load the newly created data instead of the default version stored on the internet, for the year 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = ct.read_source_emissions(gas=CO2, year=2023, p=\"/tmp\")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 15M records for this year. This is spread across multiple gas and also multiple trips in the case of boats or airplanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.select(pl.len()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of distinct source IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sec = (sdf\n",
    ".group_by(SOURCE_ID, SECTOR)\n",
    ".agg(pl.len())\n",
    ".collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of sources outside forestry and land use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sec.filter(c_sector != FORESTRY_AND_LAND_USE).select(pl.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: no source is associated with multiple sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sec.group_by(SOURCE_ID).agg(c_sector.n_unique()).filter(pl.col(SECTOR) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: no annual source should be duplicated by gas. It used to be the case with V2 release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdf\n",
    ".filter(c_temporal_granularity ==\"annual\")\n",
    ".group_by(SOURCE_ID, GAS)\n",
    ".agg(pl.len())\n",
    ".filter(pl.col(\"len\") > 1)\n",
    ".sort(by=\"len\")\n",
    ".collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: emissions should always be defined. V2 used to have empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = ct.read_source_emissions(CO2E_100YR, 2023, \"/tmp\")\n",
    "(sdf\n",
    " .select(c_emissions_quantity.is_null().alias(\"null_emissions\"), c_subsector, c_iso3_country)\n",
    " .group_by(c_subsector, \"null_emissions\")\n",
    " .agg(pl.len())\n",
    " .collect()\n",
    " .pivot(index=SUBSECTOR, on=\"null_emissions\", values=\"len\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrity checks\n",
    "\n",
    "Before uploading and publishing data, it is a good idea to run a number of checks. Frameworks such as [pandera](https://pandera.readthedocs.io/en/latest/polars.html) are very helpful to implement these checks. Here we just check that Akrotiri and Dhekelia (country code XAD) is not included, as mentioned in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ct.read_source_emissions(gas=GAS_LIST, year=2022, p=\"/tmp\")\n",
    " .filter(c_iso3_country == \"XAD\")\n",
    " .select(pl.len())\n",
    ".collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CO2e subsector data should be a superset of all sectors\n",
    "\n",
    "Here is an example of issue to investigate: one would expect the total CO2e_100yr (total emissions normalized by their CO2 equivalent) to be at least present for each sector in which emissions are reported. This is not the case for FLU, for instance for the `removals` subsector.\n",
    "\n",
    "```{admonition} CTODO\n",
    ":name: missing-co2e-subsectors\n",
    "Confirm with CT.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(tbl_rows=20):\n",
    "    print(ct.read_source_emissions(gas=GAS_LIST, year=2022, p=\"/tmp\")\n",
    "     .group_by(c_sector, c_subsector, c_gas)\n",
    "     .agg(c_emissions_quantity.sum())\n",
    "     #.filter(c_emissions_quantity < 0)\n",
    "     .sort(by=[c_sector, c_subsector, c_gas])\n",
    "     .collect()\n",
    "     .pivot(GAS, index=[SECTOR, SUBSECTOR])\n",
    "     .filter(pl.col(CO2E_100YR).is_null())\n",
    "     .filter(pl.col(CO2) != 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parquet files for country emissions\n",
    "\n",
    "As of V3, country emission data is also large enough that it should be compacted in parquet files. Note the dramatic difference:\n",
    "\n",
    "- uncompressed CSV file: 106MB\n",
    "- compressed CSV file: 6MB\n",
    "- parquet: 1MB !!\n",
    "\n",
    "As highlighted, the parquet file also has the advantage of being very efficient at extracting only the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from the official archives, read all the gases.\n",
    "\n",
    "@data_function(\"/read_country\")\n",
    "def read_country():\n",
    "    path = Path(tempfile.gettempdir()) / f\"climate-trace-countries-{ct.data.version}.parquet\"\n",
    "    print(path)\n",
    "    cdf = ct.read_country_emissions(ct.constants.GAS_LIST, archive_path=True)\n",
    "    # Optimizing to read by time and then gas.\n",
    "    # The logic being that country-specific files are already available from CT.\n",
    "    (cdf\n",
    "     .sort(by=[c_start_time,c_gas,c_iso3_country])\n",
    "      .write_parquet(path) # Not taking precautions, the file is so small.\n",
    "    )\n",
    "    return path\n",
    "\n",
    "p = read_country()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contry emissions: integrity checks\n",
    "\n",
    "In a production pipeline, before uploading the final data, we would run a number of checks again on the country emissions. Here are a few checks that we can run (and which are currently failing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = ct.read_country_emissions(parquet_path=p)\n",
    "cdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country emissions: CO2e data should be a superset of all country emissions\n",
    "\n",
    "We see that some subsectors are present in CO2 emissions but are missing in the aggregated CO2e emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(tbl_rows=20):\n",
    "    print(cdf\n",
    "     .group_by(c_sector, c_subsector, c_gas)\n",
    "     .agg(c_emissions_quantity.sum())\n",
    "     .sort(by=[c_sector, c_subsector, c_gas])\n",
    "     .pivot(GAS, index=[SECTOR, SUBSECTOR])\n",
    "     .filter(pl.col(CO2E_100YR).is_null())\n",
    "     .filter(pl.col(CO2) != 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country emissions: some countries are excluded from the dataset\n",
    "\n",
    "The Climate TRACE documentation excludes certain countries from the final release, but they are still present in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_isos = [\"XAD\", \"XCL\", \"XPI\", \"XSP\"]\n",
    "(cdf\n",
    " .filter(c_iso3_country.is_in(excluded_isos))\n",
    " .group_by([ISO3_COUNTRY, c_start_time.dt.year(), GAS, SECTOR, SUBSECTOR])\n",
    " .agg(pl.len()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the geographical information\n",
    "\n",
    "The Climate TRACE dataset also includes geographical information about the location of emissions:\n",
    "- point locations for _point sources_ (factories, power plants, ...)\n",
    "- polygons for _area sources_ (forests, transportation, ...)\n",
    "\n",
    "This comes with a few remarks:\n",
    "- all the area sources are split and aggregated at the level of the county or city. You will not be able to get sources for city block or road level. You will not see either each fire in Canada, it is all aggregated at county level.\n",
    "- the ports (seaports, airports) gather the emissions from ships and airplanes emitting at sea. It is normal then to see airports having an enormous impact on a city\n",
    "\n",
    "We are going to prepare two files: one with all the points, and one with all the polygons. We do a little bit of preprocessing work:\n",
    "\n",
    "- we deduplicate the points and the polygons, they are shared between emission sources\n",
    "- for the points, we also add administrative information: which country, region, county/city are they located in? \n",
    "\n",
    "Again, all the geographical data will be converted to the Parquet format. A new specfication for geographical features called GeoParquet provides a universal way to represent simple geographical shapes in a very compact representation. We will eventually leverage it.\n",
    "\n",
    "The following function does all the processing and returns the path to newly created Parquet files. We will later upload them to HuggingFace Hub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@data_function(\"/poly_paths\")\n",
    "def get_polys_path():\n",
    "    gases = GAS_LIST\n",
    "    polys_path = ct.data.extract_polygons(p=True, gases=gases)\n",
    "    points_path = ct.data.extract_points(p=True, gases=gases, polys=polys_path)\n",
    "    return (polys_path, points_path)\n",
    "\n",
    "(polys_path, points_path) = get_polys_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data to the Hugging Face Hub\n",
    "\n",
    "As a final step, we make the datasets available on Hugging Face as a downloadable dataset.\n",
    "\n",
    "This step will only work if you have the credentials to upload the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub.utils\n",
    "upload = False\n",
    "if upload:\n",
    "    try:\n",
    "        api = huggingface_hub.HfApi()\n",
    "        for (_, fpath) in write_data():\n",
    "            fname = os.path.basename(fpath)\n",
    "            print(fname, fpath)\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=fpath,\n",
    "                path_in_repo=fname,\n",
    "                repo_id=\"tjhunter/climate-trace\",\n",
    "                repo_type=\"dataset\",\n",
    "            )\n",
    "        fpath = read_country()\n",
    "        fname = os.path.basename(fpath)\n",
    "        print(fname, fpath)\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=fpath,\n",
    "            path_in_repo=fname,\n",
    "            repo_id=\"tjhunter/climate-trace\",\n",
    "            repo_type=\"dataset\",\n",
    "        )\n",
    "    except huggingface_hub.utils.HfHubHTTPError as e:\n",
    "        print(\"error\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}